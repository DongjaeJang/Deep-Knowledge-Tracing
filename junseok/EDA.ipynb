{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# EDA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "from numpy.linalg import svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/opt/ml/input/data/train_dataset/'\n",
    "train_df = pd.read_csv(DATA_PATH+'cv_train_data_FE.csv')\n",
    "val_df = pd.read_csv(DATA_PATH+'cv_valid_data_FE.csv')\n",
    "# test_fe_df = pd.read_pickle(DATA_PATH+'train_data_FE_0609.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    userID assessmentItemID      testId  answerCode            Timestamp  \\\n",
       "0        0       A060001001  A060000001           1  2020-03-24 00:17:11   \n",
       "1        0       A060001002  A060000001           1  2020-03-24 00:17:14   \n",
       "2        0       A060001003  A060000001           1  2020-03-24 00:17:22   \n",
       "3        0       A060001004  A060000001           1  2020-03-24 00:17:29   \n",
       "4        0       A060001005  A060000001           1  2020-03-24 00:17:36   \n",
       "5        0       A060001007  A060000001           1  2020-03-24 00:17:47   \n",
       "6        0       A060003001  A060000003           0  2020-03-26 05:52:03   \n",
       "7        0       A060003002  A060000003           1  2020-03-26 05:52:10   \n",
       "8        0       A060003003  A060000003           1  2020-03-26 05:53:14   \n",
       "9        0       A060003004  A060000003           1  2020-03-26 05:53:29   \n",
       "10       0       A060003005  A060000003           1  2020-03-26 05:53:48   \n",
       "11       0       A060003006  A060000003           1  2020-03-26 05:53:55   \n",
       "12       0       A060003007  A060000003           1  2020-03-26 05:54:11   \n",
       "13       0       A060005001  A060000005           1  2020-03-31 05:02:52   \n",
       "14       0       A060005002  A060000005           1  2020-03-31 05:03:04   \n",
       "15       0       A060005003  A060000005           1  2020-03-31 05:03:11   \n",
       "16       0       A060005004  A060000005           1  2020-03-31 05:03:26   \n",
       "17       0       A060005005  A060000005           1  2020-03-31 05:03:36   \n",
       "18       0       A060005006  A060000005           0  2020-03-31 05:05:14   \n",
       "19       0       A060005007  A060000005           1  2020-03-31 05:05:48   \n",
       "\n",
       "    KnowledgeTag  hour  dow  elapsed  grade  ...  retest  solved_disorder  \\\n",
       "0           7224     0    1      0.0      6  ...       0                0   \n",
       "1           7225     0    1      3.0      6  ...       0                0   \n",
       "2           7225     0    1      8.0      6  ...       0                0   \n",
       "3           7225     0    1      7.0      6  ...       0                0   \n",
       "4           7225     0    1      7.0      6  ...       0                0   \n",
       "5           7225     0    1     11.0      6  ...       0                1   \n",
       "6           7226     5    3      NaN      6  ...       0                0   \n",
       "7           7226     5    3      7.0      6  ...       0                0   \n",
       "8           7226     5    3     64.0      6  ...       0                0   \n",
       "9           7226     5    3     15.0      6  ...       0                0   \n",
       "10          7226     5    3     19.0      6  ...       0                0   \n",
       "11          7226     5    3      7.0      6  ...       0                0   \n",
       "12          7226     5    3     16.0      6  ...       0                0   \n",
       "13          7227     5    1      NaN      6  ...       0                0   \n",
       "14          7228     5    1     12.0      6  ...       0                0   \n",
       "15          7228     5    1      7.0      6  ...       0                0   \n",
       "16          7228     5    1     15.0      6  ...       0                0   \n",
       "17          7228     5    1     10.0      6  ...       0                0   \n",
       "18          7227     5    1     98.0      6  ...       0                0   \n",
       "19          7228     5    1     34.0      6  ...       0                0   \n",
       "\n",
       "    last_problem  answer_delta  tag_delta  test_delta  assess_delta  \\\n",
       "0              0      0.290768   0.044978    0.052317      0.017937   \n",
       "1              0      0.290768   0.086813    0.052317      0.035874   \n",
       "2              0      0.290768   0.086813    0.052317      0.089686   \n",
       "3              0      0.290768   0.086813    0.052317      0.031390   \n",
       "4              0      0.290768   0.086813    0.052317      0.058296   \n",
       "5             -1      0.290768   0.086813    0.052317      0.080717   \n",
       "6              0     -0.709232  -0.799552   -0.790562     -0.882353   \n",
       "7              0      0.290768   0.200448    0.209438      0.081448   \n",
       "8              0      0.290768   0.200448    0.209438      0.479638   \n",
       "9              0      0.290768   0.200448    0.209438      0.176471   \n",
       "10             0      0.290768   0.200448    0.209438      0.280543   \n",
       "11             0      0.290768   0.200448    0.209438      0.180995   \n",
       "12            -1      0.290768   0.200448    0.209438      0.149321   \n",
       "13             0      0.290768   0.182229    0.153748      0.053812   \n",
       "14             0      0.290768   0.173394    0.153748      0.076233   \n",
       "15             0      0.290768   0.173394    0.153748      0.228700   \n",
       "16             0      0.290768   0.173394    0.153748      0.121076   \n",
       "17             0      0.290768   0.173394    0.153748      0.098655   \n",
       "18             0     -0.709232  -0.817771   -0.846252     -0.735426   \n",
       "19            -1      0.290768   0.173394    0.153748      0.233184   \n",
       "\n",
       "    left_asymptote  elo_prob  cum_correct  \n",
       "0                0  0.979350     1.000000  \n",
       "1                0  0.970579     1.000000  \n",
       "2                0  0.942168     1.000000  \n",
       "3                0  0.972448     1.000000  \n",
       "4                0  0.957230     1.000000  \n",
       "5                0  0.947445     1.000000  \n",
       "6                0  0.912392     0.000000  \n",
       "7                0  0.937566     0.000000  \n",
       "8                0  0.628990     0.500000  \n",
       "9                0  0.871671     0.666667  \n",
       "10               0  0.744160     0.750000  \n",
       "11               0  0.877369     0.800000  \n",
       "12               0  0.878464     0.833333  \n",
       "13               0  0.956799     0.000000  \n",
       "14               0  0.942706     1.000000  \n",
       "15               0  0.794844     1.000000  \n",
       "16               0  0.904714     1.000000  \n",
       "17               0  0.933034     1.000000  \n",
       "18               0  0.819161     1.000000  \n",
       "19               0  0.771457     0.833333  \n",
       "\n",
       "[20 rows x 57 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userID</th>\n      <th>assessmentItemID</th>\n      <th>testId</th>\n      <th>answerCode</th>\n      <th>Timestamp</th>\n      <th>KnowledgeTag</th>\n      <th>hour</th>\n      <th>dow</th>\n      <th>elapsed</th>\n      <th>grade</th>\n      <th>...</th>\n      <th>retest</th>\n      <th>solved_disorder</th>\n      <th>last_problem</th>\n      <th>answer_delta</th>\n      <th>tag_delta</th>\n      <th>test_delta</th>\n      <th>assess_delta</th>\n      <th>left_asymptote</th>\n      <th>elo_prob</th>\n      <th>cum_correct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>A060001001</td>\n      <td>A060000001</td>\n      <td>1</td>\n      <td>2020-03-24 00:17:11</td>\n      <td>7224</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.290768</td>\n      <td>0.044978</td>\n      <td>0.052317</td>\n      <td>0.017937</td>\n      <td>0</td>\n      <td>0.979350</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>A060001002</td>\n      <td>A060000001</td>\n      <td>1</td>\n      <td>2020-03-24 00:17:14</td>\n      <td>7225</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.290768</td>\n      <td>0.086813</td>\n      <td>0.052317</td>\n      <td>0.035874</td>\n      <td>0</td>\n      <td>0.970579</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>A060001003</td>\n      <td>A060000001</td>\n      <td>1</td>\n      <td>2020-03-24 00:17:22</td>\n      <td>7225</td>\n      <td>0</td>\n      <td>1</td>\n      <td>8.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.290768</td>\n      <td>0.086813</td>\n      <td>0.052317</td>\n      <td>0.089686</td>\n      <td>0</td>\n      <td>0.942168</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>A060001004</td>\n      <td>A060000001</td>\n      <td>1</td>\n      <td>2020-03-24 00:17:29</td>\n      <td>7225</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.290768</td>\n      <td>0.086813</td>\n      <td>0.052317</td>\n      <td>0.031390</td>\n      <td>0</td>\n      <td>0.972448</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>A060001005</td>\n      <td>A060000001</td>\n      <td>1</td>\n      <td>2020-03-24 00:17:36</td>\n      <td>7225</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.290768</td>\n      <td>0.086813</td>\n      <td>0.052317</td>\n      <td>0.058296</td>\n      <td>0</td>\n      <td>0.957230</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0</td>\n      <td>A060001007</td>\n      <td>A060000001</td>\n      <td>1</td>\n      <td>2020-03-24 00:17:47</td>\n      <td>7225</td>\n      <td>0</td>\n      <td>1</td>\n      <td>11.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>-1</td>\n      <td>0.290768</td>\n      <td>0.086813</td>\n      <td>0.052317</td>\n      <td>0.080717</td>\n      <td>0</td>\n      <td>0.947445</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0</td>\n      <td>A060003001</td>\n      <td>A060000003</td>\n      <td>0</td>\n      <td>2020-03-26 05:52:03</td>\n      <td>7226</td>\n      <td>5</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.709232</td>\n      <td>-0.799552</td>\n      <td>-0.790562</td>\n      <td>-0.882353</td>\n      <td>0</td>\n      <td>0.912392</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0</td>\n      <td>A060003002</td>\n      <td>A060000003</td>\n      <td>1</td>\n      <td>2020-03-26 05:52:10</td>\n      <td>7226</td>\n      <td>5</td>\n      <td>3</td>\n      <td>7.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.290768</td>\n      <td>0.200448</td>\n      <td>0.209438</td>\n      <td>0.081448</td>\n      <td>0</td>\n      <td>0.937566</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0</td>\n      <td>A060003003</td>\n      <td>A060000003</td>\n      <td>1</td>\n      <td>2020-03-26 05:53:14</td>\n      <td>7226</td>\n      <td>5</td>\n      <td>3</td>\n      <td>64.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.290768</td>\n      <td>0.200448</td>\n      <td>0.209438</td>\n      <td>0.479638</td>\n      <td>0</td>\n      <td>0.628990</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0</td>\n      <td>A060003004</td>\n      <td>A060000003</td>\n      <td>1</td>\n      <td>2020-03-26 05:53:29</td>\n      <td>7226</td>\n      <td>5</td>\n      <td>3</td>\n      <td>15.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.290768</td>\n      <td>0.200448</td>\n      <td>0.209438</td>\n      <td>0.176471</td>\n      <td>0</td>\n      <td>0.871671</td>\n      <td>0.666667</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0</td>\n      <td>A060003005</td>\n      <td>A060000003</td>\n      <td>1</td>\n      <td>2020-03-26 05:53:48</td>\n      <td>7226</td>\n      <td>5</td>\n      <td>3</td>\n      <td>19.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.290768</td>\n      <td>0.200448</td>\n      <td>0.209438</td>\n      <td>0.280543</td>\n      <td>0</td>\n      <td>0.744160</td>\n      <td>0.750000</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0</td>\n      <td>A060003006</td>\n      <td>A060000003</td>\n      <td>1</td>\n      <td>2020-03-26 05:53:55</td>\n      <td>7226</td>\n      <td>5</td>\n      <td>3</td>\n      <td>7.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.290768</td>\n      <td>0.200448</td>\n      <td>0.209438</td>\n      <td>0.180995</td>\n      <td>0</td>\n      <td>0.877369</td>\n      <td>0.800000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0</td>\n      <td>A060003007</td>\n      <td>A060000003</td>\n      <td>1</td>\n      <td>2020-03-26 05:54:11</td>\n      <td>7226</td>\n      <td>5</td>\n      <td>3</td>\n      <td>16.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>0.290768</td>\n      <td>0.200448</td>\n      <td>0.209438</td>\n      <td>0.149321</td>\n      <td>0</td>\n      <td>0.878464</td>\n      <td>0.833333</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0</td>\n      <td>A060005001</td>\n      <td>A060000005</td>\n      <td>1</td>\n      <td>2020-03-31 05:02:52</td>\n      <td>7227</td>\n      <td>5</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.290768</td>\n      <td>0.182229</td>\n      <td>0.153748</td>\n      <td>0.053812</td>\n      <td>0</td>\n      <td>0.956799</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0</td>\n      <td>A060005002</td>\n      <td>A060000005</td>\n      <td>1</td>\n      <td>2020-03-31 05:03:04</td>\n      <td>7228</td>\n      <td>5</td>\n      <td>1</td>\n      <td>12.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.290768</td>\n      <td>0.173394</td>\n      <td>0.153748</td>\n      <td>0.076233</td>\n      <td>0</td>\n      <td>0.942706</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0</td>\n      <td>A060005003</td>\n      <td>A060000005</td>\n      <td>1</td>\n      <td>2020-03-31 05:03:11</td>\n      <td>7228</td>\n      <td>5</td>\n      <td>1</td>\n      <td>7.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.290768</td>\n      <td>0.173394</td>\n      <td>0.153748</td>\n      <td>0.228700</td>\n      <td>0</td>\n      <td>0.794844</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0</td>\n      <td>A060005004</td>\n      <td>A060000005</td>\n      <td>1</td>\n      <td>2020-03-31 05:03:26</td>\n      <td>7228</td>\n      <td>5</td>\n      <td>1</td>\n      <td>15.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.290768</td>\n      <td>0.173394</td>\n      <td>0.153748</td>\n      <td>0.121076</td>\n      <td>0</td>\n      <td>0.904714</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0</td>\n      <td>A060005005</td>\n      <td>A060000005</td>\n      <td>1</td>\n      <td>2020-03-31 05:03:36</td>\n      <td>7228</td>\n      <td>5</td>\n      <td>1</td>\n      <td>10.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.290768</td>\n      <td>0.173394</td>\n      <td>0.153748</td>\n      <td>0.098655</td>\n      <td>0</td>\n      <td>0.933034</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0</td>\n      <td>A060005006</td>\n      <td>A060000005</td>\n      <td>0</td>\n      <td>2020-03-31 05:05:14</td>\n      <td>7227</td>\n      <td>5</td>\n      <td>1</td>\n      <td>98.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.709232</td>\n      <td>-0.817771</td>\n      <td>-0.846252</td>\n      <td>-0.735426</td>\n      <td>0</td>\n      <td>0.819161</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0</td>\n      <td>A060005007</td>\n      <td>A060000005</td>\n      <td>1</td>\n      <td>2020-03-31 05:05:48</td>\n      <td>7228</td>\n      <td>5</td>\n      <td>1</td>\n      <td>34.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>0.290768</td>\n      <td>0.173394</td>\n      <td>0.153748</td>\n      <td>0.233184</td>\n      <td>0</td>\n      <td>0.771457</td>\n      <td>0.833333</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows × 57 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "train_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['userID', 'assessmentItemID', 'testId', 'answerCode', 'Timestamp',\n",
       "       'KnowledgeTag', 'hour', 'dow', 'elapsed', 'grade', 'mid',\n",
       "       'problem_number', 'test_mean', 'test_sum', 'tag_mean', 'tag_sum',\n",
       "       'ass_mean', 'ass_sum', 'prb_mean', 'prb_sum', 'hour_mean', 'hour_sum',\n",
       "       'dow_mean', 'dow_sum', 'tag_elp', 'tag_elp_o', 'tag_elp_x', 'ass_elp',\n",
       "       'ass_elp_o', 'ass_elp_x', 'prb_elp', 'prb_elp_o', 'prb_elp_x',\n",
       "       'user_correct_answer', 'user_total_answer', 'user_acc', 'Grade_o',\n",
       "       'GradeCount', 'GradeAcc', 'GradeElp', 'GradeMElp', 'problem_count',\n",
       "       'tag_count', 'RepeatedTime', 'prior_KnowledgeTag_frequency',\n",
       "       'problem_position', 'solve_order', 'retest', 'solved_disorder',\n",
       "       'last_problem', 'answer_delta', 'tag_delta', 'test_delta',\n",
       "       'assess_delta', 'left_asymptote', 'elo_prob', 'cum_correct'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fe_df= pd.read_csv(DATA_PATH+'train_FE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fe_df['Timestamp'] = test_fe_df['Timestamp'].apply(convert_time)\n",
    "test_fe_df.to_csv(os.path.join(\"/opt/ml/input/data/train_dataset\",\"train_FE.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_fe_df['Timestamp'].unique()\n",
    "test_fe_df.to_csv(os.path.join(\"/opt/ml/input/data/train_dataset\",\"train_FE.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fe_df.to_csv(os.path.join(\"/opt/ml/input/data/train_dataset\",\"TrainFE_lf.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(os.path.join(\"/opt/ml/input/data/train_dataset\",\"test_val.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/opt/ml/input/data/train_dataset/'\n",
    "train_df = pd.read_csv(DATA_PATH+'cv_train_data.csv', parse_dates=['Timestamp'], index_col=0)\n",
    "# train_df = train_df.sort_values(by=['userID', 'Timestamp']).reset_index(drop=True)\n",
    "val_df = pd.read_csv(DATA_PATH+'cv_valid_data.csv', parse_dates=['Timestamp'], index_col=0)\n",
    "# test_df = test_df.sort_values(by=['userID', 'Timestamp']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/opt/ml/input/data/train_dataset/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Timestamp'] = test_df['Timestamp'].apply(convert_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(os.path.join(\"/opt/ml/input/data/train_dataset\",\"train_cached.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "def convert_time(s):\n",
    "    timestamp = time.mktime(datetime.strptime(str(s), '%Y-%m-%d %H:%M:%S').timetuple())\n",
    "    return int(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "def feature_creator(exp_dir:str, col_name:str, data_dict:dict):\n",
    "    for mode, csv_file in tqdm(data_dict.items(), desc=\"processing features...\"):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df['temp_idx'] = df.index\n",
    "    \n",
    "        if df['Timestamp'].dtype == object or df['Timestamp'].dtype == \"datetime64[ns]\":\n",
    "            df['Timestamp'] = df['Timestamp'].apply(convert_time)\n",
    "        #### YOUR CODE HERE FROM HERE ####\n",
    "        # if mode == \"test\": \n",
    "            # test의 경우 다른 전처리가 필요한 경우의 분기 코드\n",
    "            # (ex) test dataset의 경우, answerCode가 일부는 -1로 마스킹되어 있음. 이를 처리하기 위한 다른 코드 필요)\n",
    "        # else:\n",
    "        df = df.sort_values(by=['userID', 'Timestamp'], axis=0)\n",
    "        df[col_name] = df['Timestamp'].diff().fillna(0)\n",
    "\n",
    "        \n",
    "        #### TO HERE ####\n",
    "\n",
    "        df = df.sort_values(by=['temp_idx'], axis=0)\n",
    "        directory = os.path.join(exp_dir,col_name)\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "        df[col_name].to_csv(os.path.join(directory,f\"{mode}.csv\"), index=False)\n",
    "\n",
    "    with open(os.path.join(directory,\"feature_desc.json\"),\"w\") as f:\n",
    "        data_dict[\"feature_name\"] = col_name\n",
    "        json.dump(data_dict,f)\n",
    "\n",
    "# data_dict = {\n",
    "#     \"train\": %Original_Train_dataset_directory_Here%,\n",
    "#     \"val\": %Original_Val_dataset_directory_Here%,\n",
    "#     \"test\": %Original_Test_dataset_directory_Here%,\n",
    "# }\n",
    "\n",
    "data_dict = {\n",
    "    \"train\": '/opt/ml/input/data/train_dataset/cv_train_cached.csv',\n",
    "    \"val\": '/opt/ml/input/data/train_dataset/cv_val_cached.csv',\n",
    "    \"test\": '/opt/ml/input/data/train_dataset/test_data.csv',\n",
    "}\n",
    "feature_creator('/opt/ml/input/data/features/', \"elapsed_time\", data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    \"train\": '/opt/ml/input/data/train_dataset/cv_train_cached.csv',\n",
    "    \"val\": '/opt/ml/input/data/train_dataset/cv_val_cached.csv',\n",
    "    \"test\": '/opt/ml/input/data/train_dataset/test_data.csv',\n",
    "}\n",
    "feature_creator('/opt/ml/input/data/features/', \"elapsed_time\", data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/opt/ml/input/data/train_dataset/test_data.csv', parse_dates=['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Timestamp']"
   ]
  },
  {
   "source": [
    "## TRAIN VS TEST\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Train과 Test는 같은 Column을 가지고 있으며, Row의 수는 다음과 같다.\n",
    "약 8.7:1의 비율이다"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns == test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train_dataset length: \", len(train_df),\"vs\", \"test_dataset length: \", len(test_df), \", \", len(train_df)/len(test_df))"
   ]
  },
  {
   "source": [
    "특히, 우리가 예측해야할 문제의 answerCode column은 0이나 1 대신 -1로 마스킹되어 있으며, 총 744개의 문제를 예측해야한다. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df['answerCode'] == -1]"
   ]
  },
  {
   "source": [
    "Train과 Test 데이터셋의 unique feature의 수"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"--- Train_dataset INFORMATIONS ---\n",
    "userID           : {train_df.userID.nunique()}\n",
    "assessmentItemID : {train_df.assessmentItemID.nunique()}\n",
    "testID           : {train_df.testId.nunique()}\n",
    "mean answer rate : {train_df.answerCode.sum() / train_df.shape[0] * 100:.2f}%\n",
    "KnowledgeTag     : {train_df.KnowledgeTag.nunique()}\n",
    "{'-'*26}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"--- Test_dataset INFORMATIONS ---\n",
    "userID           : {test_df.userID.nunique()}\n",
    "assessmentItemID : {test_df.assessmentItemID.nunique()}\n",
    "testID           : {test_df.testId.nunique()}\n",
    "mean answer rate : {test_df[test_df['answerCode'] != -1]['answerCode'].sum() / test_df.shape[0] * 100:.2f}%\n",
    "KnowledgeTag     : {test_df.KnowledgeTag.nunique()}\n",
    "{'-'*26}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique_userID = pd.unique(train_df.userID)\n",
    "train_unique_assessmentItemID = pd.unique(train_df.assessmentItemID)\n",
    "train_unique_testId = pd.unique(train_df.testId)\n",
    "train_unique_KnowledgeTag = pd.unique(train_df.KnowledgeTag)"
   ]
  },
  {
   "source": [
    "각 column의 value의 경우, userID는 하나도 일치하지 않고 나머지 comlumn 모두 일치합니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"\"\"--- Test_dataset INFORMATIONS ---\n",
    "train에는 없는 userID           : {len([i for i in tqdm(pd.unique(test_df.userID)) if i not in train_unique_userID])}\n",
    "train에는 없는 assessmentItemID : {len([i for i in tqdm(pd.unique(test_df.assessmentItemID)) if i not in train_unique_assessmentItemID])}\n",
    "train에는 없는 testID           : {len([i for i in tqdm(pd.unique(test_df.testId)) if i not in train_unique_testId])}\n",
    "train에는 없는 KnowledgeTag     : {len([i for i in tqdm(pd.unique(test_df.KnowledgeTag)) if i not in train_unique_KnowledgeTag])}\n",
    "{'-'*26}\"\"\")"
   ]
  },
  {
   "source": [
    "하지만 train 데이터셋과 test 데이터셋 간의 완전히 겹치는 데이터는 없습니다.\n",
    "answerCode가 -1인 Row를 빼면 학습 데이터로 활용가능할 것 같습니다."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(train_df, test_df, on=list(test_df.columns), how='outer', indicator='Exist')\n",
    "df['Exist'] = np.where(df.Exist == 'both', True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Exist']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(test_df.groupby('userID')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = train_df.sort_values(by=['userID','Timestamp'], axis=0)\n",
    "columns = ['userID', 'assessmentItemID', 'testId', 'answerCode', 'KnowledgeTag']\n",
    "group = new_df[columns].groupby('userID').apply(\n",
    "        lambda r: (\n",
    "            r['testId'].values, \n",
    "            r['assessmentItemID'].values,\n",
    "            r['KnowledgeTag'].values,\n",
    "            r['answerCode'].values\n",
    "        )\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[test_df['answerCode'] == -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column = train_df['assessmentItemID'].apply(lambda x : x[:3])\n",
    "new_column.name = \"grade\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df = train_df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['answerCode'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs = train_df.groupby('userID')['answerCode'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[train_df['userID'],'avg'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.sample(20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_df[lambda x : x['answerCode']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = train_df.groupby('userID')['answerCode'].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_acc = train_df.groupby('userID')['answerCode'].mean()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['userID'].apply(lambda x: user_acc[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_acc.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df"
   ]
  }
 ]
}