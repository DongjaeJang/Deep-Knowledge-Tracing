{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Matrix Factorization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "from numpy.linalg import svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "source": [
    "## Utils"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/opt/ml/input/data/train_dataset/'\n",
    "TRAIN_DATA = 'cv_train_data_FE.pkl'\n",
    "VALID_DATA = 'cv_valid_data_FE.pkl'\n",
    "TEST_DATA = 'cv_test_data_FE.pkl'\n",
    "K=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unnamed(df):\n",
    "    # Drop index column in df:\n",
    "    if \"Unnamed: 0\" in df.columns:\n",
    "        df = df.drop(columns=['Unnamed: 0'])\n",
    "        print(\"drop Unnamed: 0 column\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time(s):\n",
    "    # Convert datetime64 to int\n",
    "    timestamp = time.mktime(datetime.strptime(str(s), '%Y-%m-%d %H:%M:%S').timetuple())\n",
    "    return int(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_pkl():\n",
    "    # Convert csv dataset to pkl dataset for performance.    \n",
    "    if TRAIN_DATA[-3:]=='csv' : train_df.to_pickle(os.path.join(DATA_PATH,'cv_train_data_FE.pkl'))\n",
    "    if VALID_DATA[-3:]=='csv' : valid_df.to_pickle(os.path.join(DATA_PATH,'cv_valid_data_FE.pkl'))\n",
    "    if TEST_DATA[-3:]=='csv' : test_df.to_pickle(os.path.join(DATA_PATH,'cv_test_data_FE.pkl'))\n",
    "# csv_to_pkl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_time(df, name):\n",
    "    # Convert datetime64 to int, then save it.\n",
    "    if df['Timestamp'].dtype == object:\n",
    "        print(df['Timestamp'].dtype, df['Timestamp'].head(1))\n",
    "        print(\"Processing Timestamp...\")\n",
    "        df['Timestamp'] = df['Timestamp'].apply(convert_time)\n",
    "        print(\"Processing Timestamp done\")\n",
    "        df.to_pickle(os.path.join(DATA_PATH,f'{name}.pkl'))\n",
    "    return df\n",
    "# train_df = cache_time(train_df, 'cv_train_data_FE')\n",
    "# valid_df = cache_time(valid_df, 'cv_valid_data_FE')\n",
    "# test_df = cache_time(test_df, 'cv_test_data_FE')"
   ]
  },
  {
   "source": [
    "## Get Data and Concat Datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from disk\n",
    "get_train_data = pd.read_csv if TRAIN_DATA[-3:]=='csv' else pd.read_pickle\n",
    "get_valid_data = pd.read_csv if VALID_DATA[-3:]=='csv' else pd.read_pickle\n",
    "get_test_data = pd.read_csv if TEST_DATA[-3:]=='csv' else pd.read_pickle\n",
    "\n",
    "train_df = get_train_data(os.path.join(DATA_PATH, TRAIN_DATA))\n",
    "valid_df = get_valid_data(os.path.join(DATA_PATH, VALID_DATA))\n",
    "test_df = get_test_data(os.path.join(DATA_PATH, TEST_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train = pd.read_csv(os.path.join(DATA_PATH, 'train_data.csv'))\n",
    "original_test = pd.read_csv(os.path.join(DATA_PATH, 'test_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2266586, 260114, True, True)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Check dataset length\n",
    "len(original_train),len(original_test),len(original_train) == len(train_df) + len(valid_df),len(original_test)==len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Index(['userID', 'assessmentItemID', 'testId', 'answerCode', 'Timestamp',\n",
       "        'KnowledgeTag', 'hour', 'dow', 'elapsed', 'grade', 'mid',\n",
       "        'problem_number', 'test_mean', 'test_sum', 'tag_mean', 'tag_sum',\n",
       "        'ass_mean', 'ass_sum', 'prb_mean', 'prb_sum', 'hour_mean', 'hour_sum',\n",
       "        'dow_mean', 'dow_sum', 'tag_elp', 'tag_elp_o', 'tag_elp_x', 'ass_elp',\n",
       "        'ass_elp_o', 'ass_elp_x', 'prb_elp', 'prb_elp_o', 'prb_elp_x',\n",
       "        'user_correct_answer', 'user_total_answer', 'user_acc', 'Grade_o',\n",
       "        'GradeCount', 'GradeAcc', 'GradeElp', 'GradeMElp', 'problem_count',\n",
       "        'tag_count', 'RepeatedTime', 'prior_KnowledgeTag_frequency',\n",
       "        'problem_position', 'solve_order', 'retest', 'solved_disorder',\n",
       "        'last_problem', 'answer_delta', 'tag_delta', 'test_delta',\n",
       "        'assess_delta', 'left_asymptote', 'elo_prob', 'cum_correct'],\n",
       "       dtype='object'),\n",
       " array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True]))"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "train_df.columns, train_df.columns == valid_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['userID', 'assessmentItemID', 'testId', 'answerCode', 'Timestamp',\n",
       "       'KnowledgeTag', 'hour', 'dow', 'elapsed', 'grade', 'mid',\n",
       "       'problem_number', 'test_mean', 'test_sum', 'tag_mean', 'tag_sum',\n",
       "       'ass_mean', 'ass_sum', 'prb_mean', 'prb_sum', 'hour_mean', 'hour_sum',\n",
       "       'dow_mean', 'dow_sum', 'tag_elp', 'tag_elp_o', 'tag_elp_x', 'ass_elp',\n",
       "       'ass_elp_o', 'ass_elp_x', 'prb_elp', 'prb_elp_o', 'prb_elp_x',\n",
       "       'user_correct_answer', 'user_total_answer', 'user_acc', 'Grade_o',\n",
       "       'GradeCount', 'GradeAcc', 'GradeElp', 'GradeMElp', 'problem_count',\n",
       "       'tag_count', 'RepeatedTime', 'prior_KnowledgeTag_frequency',\n",
       "       'problem_position', 'solve_order', 'retest', 'solved_disorder',\n",
       "       'last_problem', 'answer_delta', 'tag_delta', 'test_delta',\n",
       "       'assess_delta', 'left_asymptote', 'elo_prob'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unavailable columns\n",
    "unavailable = ['cum_correct', 'answer_delta', 'tag_delta', 'test_delta', 'assess_delta']\n",
    "train_df = train_df.drop(columns=unavailable, errors='ignore')\n",
    "valid_df = valid_df.drop(columns=unavailable, errors='ignore')\n",
    "test_df = test_df.drop(columns=unavailable, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True]),\n",
       " array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True]),\n",
       " array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True]))"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Check all the dataset's columns are same.\n",
    "train_df.columns == valid_df.columns, valid_df.columns == test_df.columns, test_df.columns == train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add temporal Index and Table column for spliting.\n",
    "# 0: train, 1: valid, 2: test\n",
    "train_df['table'] = 0\n",
    "valid_df['table'] = 1\n",
    "test_df['table'] = 2\n",
    "\n",
    "train_df['temp_idx'] = train_df.index\n",
    "valid_df['temp_idx'] = valid_df.index\n",
    "test_df['temp_idx'] = test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "744"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# Get masked test rows\n",
    "masked_test_df = test_df[test_df['answerCode'] == -1]\n",
    "unmasked_test_df = test_df[test_df['answerCode'] != -1]\n",
    "len(masked_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all datasets without masked rows.\n",
    "whole_df = pd.concat([train_df, valid_df, unmasked_test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is SVD avaliable? Unknown userID and Unknown assessmentItemID in test dataset will cause problem.\n",
    "# print(\"problem? : \")\n",
    "# masked_userID = masked_test_df['userID'].unique()\n",
    "# masked_assessmentItemID = masked_test_df['assessmentItemID'].unique()\n",
    "# if any(user not in whole_df['userID'].unique() for user in tqdm(masked_userID)) or any(user not in whole_df['assessmentItemID'].unique() for user in tqdm(masked_assessmentItemID)) : \n",
    "#     raise RuntimeError(f'TSVD Feature Unavailable.')\n",
    "# print(\"nope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all df as one.\n",
    "whole_df = pd.concat([whole_df, masked_test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2526700, True)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "len(whole_df), len(whole_df) == len(train_df) + len(valid_df) + len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7442, 9454)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "len(whole_df['userID'].unique()), len(whole_df['assessmentItemID'].unique())"
   ]
  },
  {
   "source": [
    "## Truncated SVD\n",
    "- 가장 중요한 K개의 잠재요소만 가져와서 Feature로 삼는 방법"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_TSVD(k, df):\n",
    "    # Add lf function in Dataframe.\n",
    "\n",
    "    # Careate Pivot Table\n",
    "    print(\"Create Pivot Table\")\n",
    "    ans_df = df[df['answerCode'] != -1].groupby(['userID', 'assessmentItemID']).answerCode.sum().reset_index()\n",
    "    pivot_df = ans_df.pivot(index='userID', columns='assessmentItemID', values='answerCode').fillna(0)\n",
    "\n",
    "    # fit SVD    \n",
    "    print(\"fit SVD\")\n",
    "    svd2 = TruncatedSVD(n_components=k)\n",
    "    svd2.fit(pivot_df)\n",
    "    user_hid = svd2.transform(pivot_df)\n",
    "    print(\"유저 잠재요인 : \", len(user_hid), len(user_hid[0]))\n",
    "    svd2.fit(pivot_df.T)\n",
    "    problems_hid = svd2.transform(pivot_df.T)\n",
    "    print(\"문제 잠재요인 : \", len(problems_hid), len(problems_hid[0]))\n",
    "    users = pivot_df.index.values\n",
    "    problems = pivot_df.columns.values\n",
    "\n",
    "    # 유저 잠재 요인 - U\n",
    "    user_latent_factor = {}\n",
    "\n",
    "    for i, user in enumerate(users):\n",
    "        user_latent_factor[user] = user_hid[i]\n",
    "\n",
    "    # 문제 잠재 요인 - V\n",
    "    problems_latent_factor = {}\n",
    "\n",
    "    for i, problem in enumerate(problems):\n",
    "        problems_latent_factor[problem] = problems_hid[i]\n",
    "\n",
    "    print(\"assessmentItemID mapping\")\n",
    "    nested_problems_lf = df['assessmentItemID'].map(problems_latent_factor).values\n",
    "    problem_lf = np.concatenate(nested_problems_lf, 0).reshape(-1, len(nested_problems_lf[0]))\n",
    "    # Add feature\n",
    "    print(\"Add feature\")\n",
    "    df[[f'assessmentItemID_lf{i + 1}' for i in tqdm(range(k))]] = problem_lf\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Create Pivot Table\n",
      "fit SVD\n",
      "유저 잠재요인 :  7442 40\n",
      "문제 잠재요인 :  9454 40\n",
      "assessmentItemID mapping\n",
      "Add feature\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/40 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3461962991fe465d884c89cadd882d2c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         userID assessmentItemID      testId  answerCode   Timestamp  \\\n",
       "0             0       A060001001  A060000001           1  1585009031   \n",
       "1             0       A060001002  A060000001           1  1585009034   \n",
       "2             0       A060001003  A060000001           1  1585009042   \n",
       "3             0       A060001004  A060000001           1  1585009049   \n",
       "4             0       A060001005  A060000001           1  1585009056   \n",
       "...         ...              ...         ...         ...         ...   \n",
       "2526695    7395       A040122005  A040000122          -1  1599530720   \n",
       "2526696    7404       A030111005  A030000111          -1  1602582558   \n",
       "2526697    7416       A050193004  A050000193          -1  1601779481   \n",
       "2526698    7417       A050193004  A050000193          -1  1599397755   \n",
       "2526699    7439       A040130005  A040000130          -1  1602717003   \n",
       "\n",
       "         KnowledgeTag  hour  dow  elapsed  grade  ...  assessmentItemID_lf31  \\\n",
       "0                7224     0    1      0.0      6  ...               0.187618   \n",
       "1                7225     0    1      3.0      6  ...               0.189153   \n",
       "2                7225     0    1      8.0      6  ...               0.218003   \n",
       "3                7225     0    1      7.0      6  ...               0.171232   \n",
       "4                7225     0    1      7.0      6  ...               0.117933   \n",
       "...               ...   ...  ...      ...    ...  ...                    ...   \n",
       "2526695         10615     2    1      2.0      4  ...              -0.050888   \n",
       "2526696          7636     9    1    107.0      3  ...              -0.167530   \n",
       "2526697         10402     2    6     24.0      5  ...               0.567810   \n",
       "2526698         10402    13    6     21.0      5  ...               0.567810   \n",
       "2526699          8832    23    2     32.0      4  ...              -0.273094   \n",
       "\n",
       "         assessmentItemID_lf32  assessmentItemID_lf33  assessmentItemID_lf34  \\\n",
       "0                     0.105149               0.089573               0.112876   \n",
       "1                     0.069678               0.095991               0.108613   \n",
       "2                     0.211369               0.035524               0.105588   \n",
       "3                     0.112103               0.011979               0.137871   \n",
       "4                    -0.010957               0.008431               0.148195   \n",
       "...                        ...                    ...                    ...   \n",
       "2526695              -0.443437              -0.862972              -2.402245   \n",
       "2526696               0.367423              -0.258267               0.378479   \n",
       "2526697               0.538026              -0.776257              -0.397721   \n",
       "2526698               0.538026              -0.776257              -0.397721   \n",
       "2526699              -0.535442              -1.357537              -3.439956   \n",
       "\n",
       "         assessmentItemID_lf35  assessmentItemID_lf36  assessmentItemID_lf37  \\\n",
       "0                     0.034190               1.387534              -0.477091   \n",
       "1                     0.036473               1.353113              -0.455818   \n",
       "2                     0.023566               1.401665              -0.460065   \n",
       "3                     0.021363               1.368139              -0.464908   \n",
       "4                     0.035449               1.288530              -0.435120   \n",
       "...                        ...                    ...                    ...   \n",
       "2526695               0.919398              -0.045741              -0.734190   \n",
       "2526696              -0.139851               0.137944              -0.224567   \n",
       "2526697              -1.008641               0.142540               0.355269   \n",
       "2526698              -1.008641               0.142540               0.355269   \n",
       "2526699               1.107855               0.105793              -1.161625   \n",
       "\n",
       "         assessmentItemID_lf38  assessmentItemID_lf39  assessmentItemID_lf40  \n",
       "0                     0.010622              -0.637065              -1.116152  \n",
       "1                     0.008808              -0.701690              -1.191159  \n",
       "2                     0.097230              -0.542106              -1.003339  \n",
       "3                     0.005286              -0.630683              -1.098972  \n",
       "4                    -0.023752              -0.634095              -1.050310  \n",
       "...                        ...                    ...                    ...  \n",
       "2526695              -0.077270              -0.013150              -0.664047  \n",
       "2526696              -0.084782               0.717462               0.150860  \n",
       "2526697               6.712777               0.723459              -0.708221  \n",
       "2526698               6.712777               0.723459              -0.708221  \n",
       "2526699              -0.494018               0.018788              -0.924167  \n",
       "\n",
       "[2526700 rows x 94 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userID</th>\n      <th>assessmentItemID</th>\n      <th>testId</th>\n      <th>answerCode</th>\n      <th>Timestamp</th>\n      <th>KnowledgeTag</th>\n      <th>hour</th>\n      <th>dow</th>\n      <th>elapsed</th>\n      <th>grade</th>\n      <th>...</th>\n      <th>assessmentItemID_lf31</th>\n      <th>assessmentItemID_lf32</th>\n      <th>assessmentItemID_lf33</th>\n      <th>assessmentItemID_lf34</th>\n      <th>assessmentItemID_lf35</th>\n      <th>assessmentItemID_lf36</th>\n      <th>assessmentItemID_lf37</th>\n      <th>assessmentItemID_lf38</th>\n      <th>assessmentItemID_lf39</th>\n      <th>assessmentItemID_lf40</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>A060001001</td>\n      <td>A060000001</td>\n      <td>1</td>\n      <td>1585009031</td>\n      <td>7224</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0.187618</td>\n      <td>0.105149</td>\n      <td>0.089573</td>\n      <td>0.112876</td>\n      <td>0.034190</td>\n      <td>1.387534</td>\n      <td>-0.477091</td>\n      <td>0.010622</td>\n      <td>-0.637065</td>\n      <td>-1.116152</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>A060001002</td>\n      <td>A060000001</td>\n      <td>1</td>\n      <td>1585009034</td>\n      <td>7225</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0.189153</td>\n      <td>0.069678</td>\n      <td>0.095991</td>\n      <td>0.108613</td>\n      <td>0.036473</td>\n      <td>1.353113</td>\n      <td>-0.455818</td>\n      <td>0.008808</td>\n      <td>-0.701690</td>\n      <td>-1.191159</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>A060001003</td>\n      <td>A060000001</td>\n      <td>1</td>\n      <td>1585009042</td>\n      <td>7225</td>\n      <td>0</td>\n      <td>1</td>\n      <td>8.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0.218003</td>\n      <td>0.211369</td>\n      <td>0.035524</td>\n      <td>0.105588</td>\n      <td>0.023566</td>\n      <td>1.401665</td>\n      <td>-0.460065</td>\n      <td>0.097230</td>\n      <td>-0.542106</td>\n      <td>-1.003339</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>A060001004</td>\n      <td>A060000001</td>\n      <td>1</td>\n      <td>1585009049</td>\n      <td>7225</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0.171232</td>\n      <td>0.112103</td>\n      <td>0.011979</td>\n      <td>0.137871</td>\n      <td>0.021363</td>\n      <td>1.368139</td>\n      <td>-0.464908</td>\n      <td>0.005286</td>\n      <td>-0.630683</td>\n      <td>-1.098972</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>A060001005</td>\n      <td>A060000001</td>\n      <td>1</td>\n      <td>1585009056</td>\n      <td>7225</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>0.117933</td>\n      <td>-0.010957</td>\n      <td>0.008431</td>\n      <td>0.148195</td>\n      <td>0.035449</td>\n      <td>1.288530</td>\n      <td>-0.435120</td>\n      <td>-0.023752</td>\n      <td>-0.634095</td>\n      <td>-1.050310</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2526695</th>\n      <td>7395</td>\n      <td>A040122005</td>\n      <td>A040000122</td>\n      <td>-1</td>\n      <td>1599530720</td>\n      <td>10615</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>-0.050888</td>\n      <td>-0.443437</td>\n      <td>-0.862972</td>\n      <td>-2.402245</td>\n      <td>0.919398</td>\n      <td>-0.045741</td>\n      <td>-0.734190</td>\n      <td>-0.077270</td>\n      <td>-0.013150</td>\n      <td>-0.664047</td>\n    </tr>\n    <tr>\n      <th>2526696</th>\n      <td>7404</td>\n      <td>A030111005</td>\n      <td>A030000111</td>\n      <td>-1</td>\n      <td>1602582558</td>\n      <td>7636</td>\n      <td>9</td>\n      <td>1</td>\n      <td>107.0</td>\n      <td>3</td>\n      <td>...</td>\n      <td>-0.167530</td>\n      <td>0.367423</td>\n      <td>-0.258267</td>\n      <td>0.378479</td>\n      <td>-0.139851</td>\n      <td>0.137944</td>\n      <td>-0.224567</td>\n      <td>-0.084782</td>\n      <td>0.717462</td>\n      <td>0.150860</td>\n    </tr>\n    <tr>\n      <th>2526697</th>\n      <td>7416</td>\n      <td>A050193004</td>\n      <td>A050000193</td>\n      <td>-1</td>\n      <td>1601779481</td>\n      <td>10402</td>\n      <td>2</td>\n      <td>6</td>\n      <td>24.0</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0.567810</td>\n      <td>0.538026</td>\n      <td>-0.776257</td>\n      <td>-0.397721</td>\n      <td>-1.008641</td>\n      <td>0.142540</td>\n      <td>0.355269</td>\n      <td>6.712777</td>\n      <td>0.723459</td>\n      <td>-0.708221</td>\n    </tr>\n    <tr>\n      <th>2526698</th>\n      <td>7417</td>\n      <td>A050193004</td>\n      <td>A050000193</td>\n      <td>-1</td>\n      <td>1599397755</td>\n      <td>10402</td>\n      <td>13</td>\n      <td>6</td>\n      <td>21.0</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0.567810</td>\n      <td>0.538026</td>\n      <td>-0.776257</td>\n      <td>-0.397721</td>\n      <td>-1.008641</td>\n      <td>0.142540</td>\n      <td>0.355269</td>\n      <td>6.712777</td>\n      <td>0.723459</td>\n      <td>-0.708221</td>\n    </tr>\n    <tr>\n      <th>2526699</th>\n      <td>7439</td>\n      <td>A040130005</td>\n      <td>A040000130</td>\n      <td>-1</td>\n      <td>1602717003</td>\n      <td>8832</td>\n      <td>23</td>\n      <td>2</td>\n      <td>32.0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>-0.273094</td>\n      <td>-0.535442</td>\n      <td>-1.357537</td>\n      <td>-3.439956</td>\n      <td>1.107855</td>\n      <td>0.105793</td>\n      <td>-1.161625</td>\n      <td>-0.494018</td>\n      <td>0.018788</td>\n      <td>-0.924167</td>\n    </tr>\n  </tbody>\n</table>\n<p>2526700 rows × 94 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# truncatedSVD\n",
    "new_df = save_TSVD(K, whole_df)\n",
    "new_df"
   ]
  },
  {
   "source": [
    "## Split dataframe and Save it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = whole_df[whole_df['table']==0].sort_values(by='temp_idx').drop(columns=['table', 'temp_idx']).to_pickle(os.path.join(DATA_PATH,f'cv_train_data_FE_MF{K}.pkl'))\n",
    "valid_df = whole_df[whole_df['table']==1].sort_values(by='temp_idx').drop(columns=['table', 'temp_idx']).to_pickle(os.path.join(DATA_PATH,f'cv_valid_data_FE_MF{K}.pkl'))\n",
    "test_df = whole_df[whole_df['table']==2].sort_values(by='temp_idx').drop(columns=['table', 'temp_idx']).to_pickle(os.path.join(DATA_PATH,f'cv_test_data_FE_MF{K}.pkl'))\n",
    "\n"
   ]
  },
  {
   "source": [
    "## SVD\n",
    "memory overflow! unavaliable!  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Unavailable!",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c9793f5eda2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# untruncated svd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unavailable!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pivot_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unavailable!"
     ]
    }
   ],
   "source": [
    "# untruncated svd\n",
    "raise RuntimeError(\"Unavailable!\")\n",
    "U, sigma, VT = svd(np.array(test_pivot_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smat= np.zeros((len(U),len(VT)))\n",
    "smat[:len(U),:len(U)] = np.diag(sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = test_pivot_df.index.values\n",
    "problems = test_pivot_df.columns.values\n",
    "\n",
    "# 유저 잠재 요인 - U\n",
    "user_latent_factor = {}\n",
    "\n",
    "# scaling\n",
    "U = U @ np.diag(sigma)\n",
    "\n",
    "for i, user in enumerate(users):\n",
    "    user_latent_factor[user] = U[i]\n",
    "\n",
    "# 문제 잠재 요인 - V\n",
    "problems_latent_factor = {}\n",
    "\n",
    "# scaling\n",
    "# VT = np.diag(sigma) @ VT\n",
    "VT = smat @ VT\n",
    "\n",
    "for i, problem in enumerate(problems):\n",
    "    problems_latent_factor[problem] = VT.T[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'TruncatedSVD' object is not callable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-eefdad3eeb8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 문제 잠재 요인들을 각 문제에 mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnested_problems_lf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_svd_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'assessmentItemID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblems_latent_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   3907\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3908\u001b[0m         \"\"\"\n\u001b[0;32m-> 3909\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3910\u001b[0m         return self._constructor(new_values, index=self.index).__finalize__(\n\u001b[1;32m   3911\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"map\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;31m# mapper is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'TruncatedSVD' object is not callable"
     ]
    }
   ],
   "source": [
    "# 문제 잠재 요인들을 각 문제에 mapping\n",
    "nested_problems_lf = test_svd_df['assessmentItemID'].map(problems_latent_factor).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nested numpy array를 하나의 numpy array로 변환\n",
    "problem_lf = np.concatenate(nested_problems_lf, 0).reshape(-1, nested_problems_lf[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 문제 잠재 요인을 기존 pandas DataFrame에 추가\n",
    "test_fe_df[[f'assessmentItemID_lf{i + 1}' for i in range(3)]] = problem_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fe_df"
   ]
  }
 ]
}