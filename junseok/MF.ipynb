{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Matrix Factorization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "from numpy.linalg import svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "source": [
    "## Utils"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/opt/ml/input/data/train_dataset/'\n",
    "TRAIN_DATA = 'cv_train_FE.pkl'\n",
    "VALID_DATA = 'cv_valid_FE.pkl'\n",
    "TEST_DATA = 'test_FE.pkl'\n",
    "K=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unnamed(df):\n",
    "    # Drop index column in df:\n",
    "    if \"Unnamed: 0\" in df.columns:\n",
    "        df = df.drop(columns=['Unnamed: 0'])\n",
    "        print(\"drop Unnamed: 0 column\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_time(s):\n",
    "    # Convert datetime64 to int\n",
    "    timestamp = time.mktime(datetime.strptime(str(s), '%Y-%m-%d %H:%M:%S').timetuple())\n",
    "    return int(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_pkl():\n",
    "    # Convert csv dataset to pkl dataset for performance.    \n",
    "    if TRAIN_DATA[-3:]=='csv' : train_df.to_pickle(os.path.join(DATA_PATH,'cv_train_data_FE.pkl'))\n",
    "    if VALID_DATA[-3:]=='csv' : valid_df.to_pickle(os.path.join(DATA_PATH,'cv_valid_data_FE.pkl'))\n",
    "    if TEST_DATA[-3:]=='csv' : test_df.to_pickle(os.path.join(DATA_PATH,'cv_test_data_FE.pkl'))\n",
    "csv_to_pkl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_time(df, name):\n",
    "    # Convert datetime64 to int, then save it.\n",
    "    if df['Timestamp'].dtype == object:\n",
    "        print(df['Timestamp'].dtype, df['Timestamp'].head(1))\n",
    "        print(\"Processing Timestamp...\")\n",
    "        df['Timestamp'] = df['Timestamp'].apply(convert_time)\n",
    "        print(\"Processing Timestamp done\")\n",
    "        df.to_pickle(os.path.join(DATA_PATH,f'{name}.pkl'))\n",
    "    return df\n",
    "train_df = cache_time(train_df, 'cv_train_FE')\n",
    "valid_df = cache_time(valid_df, 'cv_valid_FE')\n",
    "test_df = cache_time(test_df, 'test_FE')"
   ]
  },
  {
   "source": [
    "## Get Data and Concat Datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from disk\n",
    "get_train_data = pd.read_csv if TRAIN_DATA[-3:]=='csv' else pd.read_pickle\n",
    "get_valid_data = pd.read_csv if VALID_DATA[-3:]=='csv' else pd.read_pickle\n",
    "get_test_data = pd.read_csv if TEST_DATA[-3:]=='csv' else pd.read_pickle\n",
    "\n",
    "train_df = get_train_data(os.path.join(DATA_PATH, TRAIN_DATA))\n",
    "valid_df = get_valid_data(os.path.join(DATA_PATH, VALID_DATA))\n",
    "test_df = get_test_data(os.path.join(DATA_PATH, TEST_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_train = pd.read_csv(os.path.join(DATA_PATH, 'train_data.csv'))\n",
    "original_test = pd.read_csv(os.path.join(DATA_PATH, 'test_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2266586, 260114, True, True)"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# Check dataset length\n",
    "len(original_train),len(original_test),len(original_train) == len(train_df) + len(valid_df),len(original_test)==len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Index(['userID', 'assessmentItemID', 'testId', 'answerCode', 'Timestamp',\n",
       "        'KnowledgeTag', 'hour', 'dow', 'elapsed', 'grade', 'mid',\n",
       "        'problem_number', 'test_mean', 'test_sum', 'tag_mean', 'tag_sum',\n",
       "        'ass_mean', 'ass_sum', 'prb_mean', 'prb_sum', 'hour_mean', 'hour_sum',\n",
       "        'dow_mean', 'dow_sum', 'tag_elp', 'tag_elp_o', 'tag_elp_x', 'ass_elp',\n",
       "        'ass_elp_o', 'ass_elp_x', 'prb_elp', 'prb_elp_o', 'prb_elp_x',\n",
       "        'user_correct_answer', 'user_total_answer', 'user_acc', 'Grade_o',\n",
       "        'GradeCount', 'GradeAcc', 'GradeElp', 'GradeMElp', 'problem_count',\n",
       "        'tag_count', 'RepeatedTime', 'prior_KnowledgeTag_frequency',\n",
       "        'problem_position', 'solve_order', 'retest', 'solved_disorder',\n",
       "        'last_problem', 'answer_delta', 'tag_delta', 'test_delta',\n",
       "        'assess_delta', 'left_asymptote', 'elo_prob', 'cum_correct',\n",
       "        'prior_relative_assess_ac_sum', 'prior_relative_answer_ac_sum',\n",
       "        'prior_relative_tag_ac_sum', 'prior_relative_test_ac_sum'],\n",
       "       dtype='object'),\n",
       " array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True]),\n",
       " 61)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "train_df.columns, train_df.columns == valid_df.columns, len(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Index(['userID', 'assessmentItemID', 'testId', 'answerCode', 'Timestamp',\n",
       "        'KnowledgeTag', 'hour', 'dow', 'elapsed', 'grade', 'mid',\n",
       "        'problem_number', 'test_mean', 'test_sum', 'tag_mean', 'tag_sum',\n",
       "        'ass_mean', 'ass_sum', 'prb_mean', 'prb_sum', 'hour_mean', 'hour_sum',\n",
       "        'dow_mean', 'dow_sum', 'tag_elp', 'tag_elp_o', 'tag_elp_x', 'ass_elp',\n",
       "        'ass_elp_o', 'ass_elp_x', 'prb_elp', 'prb_elp_o', 'prb_elp_x',\n",
       "        'user_correct_answer', 'user_total_answer', 'user_acc', 'Grade_o',\n",
       "        'GradeCount', 'GradeAcc', 'GradeElp', 'GradeMElp', 'problem_count',\n",
       "        'tag_count', 'RepeatedTime', 'prior_KnowledgeTag_frequency',\n",
       "        'problem_position', 'solve_order', 'retest', 'solved_disorder',\n",
       "        'last_problem', 'answer_delta', 'tag_delta', 'test_delta',\n",
       "        'assess_delta', 'left_asymptote', 'elo_prob',\n",
       "        'prior_relative_assess_ac_sum', 'prior_relative_answer_ac_sum',\n",
       "        'prior_relative_tag_ac_sum', 'prior_relative_test_ac_sum'],\n",
       "       dtype='object'),\n",
       " 60)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "test_df.columns, len(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        userID assessmentItemID      testId  answerCode   Timestamp  \\\n",
       "0            3       A050023001  A050000023           1  1578567391   \n",
       "1            3       A050023002  A050000023           1  1578567417   \n",
       "2            3       A050023003  A050000023           0  1578567511   \n",
       "3            3       A050023004  A050000023           0  1578567516   \n",
       "4            3       A050023006  A050000023           0  1578567523   \n",
       "...        ...              ...         ...         ...         ...   \n",
       "260109    7439       A040130001  A040000130           0  1602716843   \n",
       "260110    7439       A040130002  A040000130           1  1602716861   \n",
       "260111    7439       A040130003  A040000130           1  1602716882   \n",
       "260112    7439       A040130004  A040000130           1  1602716971   \n",
       "260113    7439       A040130005  A040000130          -1  1602717003   \n",
       "\n",
       "        KnowledgeTag  hour  dow  elapsed  grade  ...  answer_delta  tag_delta  \\\n",
       "0               2626    10    3      0.0      5  ...      0.000000   0.000000   \n",
       "1               2626    10    3     26.0      5  ...      0.337382   0.412903   \n",
       "2               2625    10    3     94.0      5  ...      0.337382   0.412903   \n",
       "3               2625    10    3      5.0      5  ...     -0.662618  -0.588517   \n",
       "4               2623    10    3      7.0      5  ...     -0.662618  -0.588517   \n",
       "...              ...   ...  ...      ...    ...  ...           ...        ...   \n",
       "260109          8832    23    2      0.0      4  ...      0.355276   0.136364   \n",
       "260110          8832    23    2     18.0      4  ...     -0.644724   0.136364   \n",
       "260111          8244    23    2     21.0      4  ...      0.355276   0.136364   \n",
       "260112          8244    23    2     89.0      4  ...      0.355276  -0.776087   \n",
       "260113          8832    23    2     32.0      4  ...      0.355276  -0.776087   \n",
       "\n",
       "        test_delta  assess_delta  left_asymptote  elo_prob  \\\n",
       "0         0.000000      0.000000               0  0.752296   \n",
       "1         0.526786      0.250000               0  0.416693   \n",
       "2         0.526786      0.437500               0  0.281076   \n",
       "3        -0.473214     -0.343750               0  0.382929   \n",
       "4        -0.473214     -0.500000               0  0.166432   \n",
       "...            ...           ...             ...       ...   \n",
       "260109    0.255208      0.125000               0  0.132075   \n",
       "260110   -0.604762     -0.380952               0  0.410814   \n",
       "260111    0.395238      0.476190               0  0.621880   \n",
       "260112    0.395238      0.238095               0  0.760312   \n",
       "260113    0.395238      0.142857               0  0.221060   \n",
       "\n",
       "        prior_relative_assess_ac_sum  prior_relative_answer_ac_sum  \\\n",
       "0                           0.000000                      0.000000   \n",
       "1                           0.250000                      0.337382   \n",
       "2                           0.687500                      0.674764   \n",
       "3                           0.343750                      0.012146   \n",
       "4                          -0.156250                     -0.650472   \n",
       "...                              ...                           ...   \n",
       "260109                     -0.711993                      0.908039   \n",
       "260110                     -1.092946                      0.263315   \n",
       "260111                     -0.616755                      0.618591   \n",
       "260112                     -0.378660                      0.973867   \n",
       "260113                     -0.235803                      1.329144   \n",
       "\n",
       "        prior_relative_tag_ac_sum  prior_relative_test_ac_sum  \n",
       "0                        0.000000                    0.000000  \n",
       "1                        0.412903                    0.526786  \n",
       "2                        0.825806                    1.053571  \n",
       "3                        0.237290                    0.580357  \n",
       "4                       -0.351227                    0.107143  \n",
       "...                           ...                         ...  \n",
       "260109                   0.370093                   -0.711993  \n",
       "260110                   0.506456                   -1.316755  \n",
       "260111                   0.642820                   -0.921517  \n",
       "260112                  -0.133267                   -0.526279  \n",
       "260113                  -0.909354                   -0.131041  \n",
       "\n",
       "[260114 rows x 60 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userID</th>\n      <th>assessmentItemID</th>\n      <th>testId</th>\n      <th>answerCode</th>\n      <th>Timestamp</th>\n      <th>KnowledgeTag</th>\n      <th>hour</th>\n      <th>dow</th>\n      <th>elapsed</th>\n      <th>grade</th>\n      <th>...</th>\n      <th>answer_delta</th>\n      <th>tag_delta</th>\n      <th>test_delta</th>\n      <th>assess_delta</th>\n      <th>left_asymptote</th>\n      <th>elo_prob</th>\n      <th>prior_relative_assess_ac_sum</th>\n      <th>prior_relative_answer_ac_sum</th>\n      <th>prior_relative_tag_ac_sum</th>\n      <th>prior_relative_test_ac_sum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>A050023001</td>\n      <td>A050000023</td>\n      <td>1</td>\n      <td>1578567391</td>\n      <td>2626</td>\n      <td>10</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0</td>\n      <td>0.752296</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>A050023002</td>\n      <td>A050000023</td>\n      <td>1</td>\n      <td>1578567417</td>\n      <td>2626</td>\n      <td>10</td>\n      <td>3</td>\n      <td>26.0</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0.337382</td>\n      <td>0.412903</td>\n      <td>0.526786</td>\n      <td>0.250000</td>\n      <td>0</td>\n      <td>0.416693</td>\n      <td>0.250000</td>\n      <td>0.337382</td>\n      <td>0.412903</td>\n      <td>0.526786</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>A050023003</td>\n      <td>A050000023</td>\n      <td>0</td>\n      <td>1578567511</td>\n      <td>2625</td>\n      <td>10</td>\n      <td>3</td>\n      <td>94.0</td>\n      <td>5</td>\n      <td>...</td>\n      <td>0.337382</td>\n      <td>0.412903</td>\n      <td>0.526786</td>\n      <td>0.437500</td>\n      <td>0</td>\n      <td>0.281076</td>\n      <td>0.687500</td>\n      <td>0.674764</td>\n      <td>0.825806</td>\n      <td>1.053571</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>A050023004</td>\n      <td>A050000023</td>\n      <td>0</td>\n      <td>1578567516</td>\n      <td>2625</td>\n      <td>10</td>\n      <td>3</td>\n      <td>5.0</td>\n      <td>5</td>\n      <td>...</td>\n      <td>-0.662618</td>\n      <td>-0.588517</td>\n      <td>-0.473214</td>\n      <td>-0.343750</td>\n      <td>0</td>\n      <td>0.382929</td>\n      <td>0.343750</td>\n      <td>0.012146</td>\n      <td>0.237290</td>\n      <td>0.580357</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>A050023006</td>\n      <td>A050000023</td>\n      <td>0</td>\n      <td>1578567523</td>\n      <td>2623</td>\n      <td>10</td>\n      <td>3</td>\n      <td>7.0</td>\n      <td>5</td>\n      <td>...</td>\n      <td>-0.662618</td>\n      <td>-0.588517</td>\n      <td>-0.473214</td>\n      <td>-0.500000</td>\n      <td>0</td>\n      <td>0.166432</td>\n      <td>-0.156250</td>\n      <td>-0.650472</td>\n      <td>-0.351227</td>\n      <td>0.107143</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>260109</th>\n      <td>7439</td>\n      <td>A040130001</td>\n      <td>A040000130</td>\n      <td>0</td>\n      <td>1602716843</td>\n      <td>8832</td>\n      <td>23</td>\n      <td>2</td>\n      <td>0.0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0.355276</td>\n      <td>0.136364</td>\n      <td>0.255208</td>\n      <td>0.125000</td>\n      <td>0</td>\n      <td>0.132075</td>\n      <td>-0.711993</td>\n      <td>0.908039</td>\n      <td>0.370093</td>\n      <td>-0.711993</td>\n    </tr>\n    <tr>\n      <th>260110</th>\n      <td>7439</td>\n      <td>A040130002</td>\n      <td>A040000130</td>\n      <td>1</td>\n      <td>1602716861</td>\n      <td>8832</td>\n      <td>23</td>\n      <td>2</td>\n      <td>18.0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>-0.644724</td>\n      <td>0.136364</td>\n      <td>-0.604762</td>\n      <td>-0.380952</td>\n      <td>0</td>\n      <td>0.410814</td>\n      <td>-1.092946</td>\n      <td>0.263315</td>\n      <td>0.506456</td>\n      <td>-1.316755</td>\n    </tr>\n    <tr>\n      <th>260111</th>\n      <td>7439</td>\n      <td>A040130003</td>\n      <td>A040000130</td>\n      <td>1</td>\n      <td>1602716882</td>\n      <td>8244</td>\n      <td>23</td>\n      <td>2</td>\n      <td>21.0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0.355276</td>\n      <td>0.136364</td>\n      <td>0.395238</td>\n      <td>0.476190</td>\n      <td>0</td>\n      <td>0.621880</td>\n      <td>-0.616755</td>\n      <td>0.618591</td>\n      <td>0.642820</td>\n      <td>-0.921517</td>\n    </tr>\n    <tr>\n      <th>260112</th>\n      <td>7439</td>\n      <td>A040130004</td>\n      <td>A040000130</td>\n      <td>1</td>\n      <td>1602716971</td>\n      <td>8244</td>\n      <td>23</td>\n      <td>2</td>\n      <td>89.0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0.355276</td>\n      <td>-0.776087</td>\n      <td>0.395238</td>\n      <td>0.238095</td>\n      <td>0</td>\n      <td>0.760312</td>\n      <td>-0.378660</td>\n      <td>0.973867</td>\n      <td>-0.133267</td>\n      <td>-0.526279</td>\n    </tr>\n    <tr>\n      <th>260113</th>\n      <td>7439</td>\n      <td>A040130005</td>\n      <td>A040000130</td>\n      <td>-1</td>\n      <td>1602717003</td>\n      <td>8832</td>\n      <td>23</td>\n      <td>2</td>\n      <td>32.0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>0.355276</td>\n      <td>-0.776087</td>\n      <td>0.395238</td>\n      <td>0.142857</td>\n      <td>0</td>\n      <td>0.221060</td>\n      <td>-0.235803</td>\n      <td>1.329144</td>\n      <td>-0.909354</td>\n      <td>-0.131041</td>\n    </tr>\n  </tbody>\n</table>\n<p>260114 rows × 60 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unavailable columns\n",
    "# raise RuntimeError(\"Preventing Error!\")\n",
    "unavailable = ['cum_correct']\n",
    "train_df = train_df.drop(columns=unavailable, errors='ignore')\n",
    "valid_df = valid_df.drop(columns=unavailable, errors='ignore')\n",
    "test_df = test_df.drop(columns=unavailable, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True]),\n",
       " array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True]),\n",
       " array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True]))"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# Check all the dataset's columns are same.\n",
    "train_df.columns == valid_df.columns, valid_df.columns == test_df.columns, test_df.columns == train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add temporal Index and Table column for spliting.\n",
    "# 0: train, 1: valid, 2: test\n",
    "train_df['table'] = 0\n",
    "valid_df['table'] = 1\n",
    "test_df['table'] = 2\n",
    "\n",
    "train_df['temp_idx'] = train_df.index\n",
    "valid_df['temp_idx'] = valid_df.index\n",
    "test_df['temp_idx'] = test_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "744"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# Get masked test rows\n",
    "masked_test_df = test_df[test_df['answerCode'] == -1]\n",
    "unmasked_test_df = test_df[test_df['answerCode'] != -1]\n",
    "len(masked_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all datasets without masked rows.\n",
    "whole_df = pd.concat([train_df, valid_df, unmasked_test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "problem? : \n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/744 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40f8ed81a2ed4b7bbccaf79374bf07a7"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/444 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "804aa4d3bf444ae1b2ccb99b455f1984"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "nope, Happy hacking!\n"
     ]
    }
   ],
   "source": [
    "# Is SVD avaliable? Unknown userID and Unknown assessmentItemID in test dataset will cause problem.\n",
    "print(\"problem? : \")\n",
    "masked_userID = masked_test_df['userID'].unique()\n",
    "masked_assessmentItemID = masked_test_df['assessmentItemID'].unique()\n",
    "if any(user not in whole_df['userID'].unique() for user in tqdm(masked_userID)) or any(user not in whole_df['assessmentItemID'].unique() for user in tqdm(masked_assessmentItemID)) : \n",
    "    raise RuntimeError(f'TSVD Feature Unavailable.')\n",
    "print(\"nope, Happy hacking!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat all df as one.\n",
    "whole_df = pd.concat([whole_df, masked_test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(2526700, True)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "len(whole_df), len(whole_df) == len(train_df) + len(valid_df) + len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7442, 9454)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "len(whole_df['userID'].unique()), len(whole_df['assessmentItemID'].unique())"
   ]
  },
  {
   "source": [
    "## Truncated SVD\n",
    "- 가장 중요한 K개의 잠재요소만 가져와서 Feature로 삼는 방법"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_TSVD(k, df):\n",
    "    # Add lf function in Dataframe.\n",
    "\n",
    "    # Careate Pivot Table\n",
    "    print(\"Create Pivot Table\")\n",
    "    ans_df = df[df['answerCode'] != -1].groupby(['userID', 'assessmentItemID']).answerCode.sum().reset_index()\n",
    "    pivot_df = ans_df.pivot(index='userID', columns='assessmentItemID', values='answerCode').fillna(0)\n",
    "\n",
    "    # fit SVD    \n",
    "    print(\"fit SVD\")\n",
    "    svd2 = TruncatedSVD(n_components=k)\n",
    "    svd2.fit(pivot_df)\n",
    "    user_hid = svd2.transform(pivot_df)\n",
    "    print(\"유저 잠재요인 : \", len(user_hid), len(user_hid[0]))\n",
    "    svd2.fit(pivot_df.T)\n",
    "    problems_hid = svd2.transform(pivot_df.T)\n",
    "    print(\"문제 잠재요인 : \", len(problems_hid), len(problems_hid[0]))\n",
    "    users = pivot_df.index.values\n",
    "    problems = pivot_df.columns.values\n",
    "\n",
    "    # 유저 잠재 요인 - U\n",
    "    user_latent_factor = {}\n",
    "\n",
    "    for i, user in enumerate(users):\n",
    "        user_latent_factor[user] = user_hid[i]\n",
    "\n",
    "    # 문제 잠재 요인 - V\n",
    "    problems_latent_factor = {}\n",
    "\n",
    "    for i, problem in enumerate(problems):\n",
    "        problems_latent_factor[problem] = problems_hid[i]\n",
    "\n",
    "    print(\"assessmentItemID mapping\")\n",
    "    nested_problems_lf = df['assessmentItemID'].map(problems_latent_factor).values\n",
    "    problem_lf = np.concatenate(nested_problems_lf, 0).reshape(-1, len(nested_problems_lf[0]))\n",
    "    # Add feature\n",
    "    print(\"Add feature\")\n",
    "    df[[f'assessmentItemID_lf{i + 1}' for i in tqdm(range(k))]] = problem_lf\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Create Pivot Table\n",
      "fit SVD\n",
      "유저 잠재요인 :  7442 10\n",
      "문제 잠재요인 :  9454 10\n",
      "assessmentItemID mapping\n",
      "Add feature\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/10 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21c92a207be44479930e5858a587a26d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         userID assessmentItemID      testId  answerCode   Timestamp  \\\n",
       "0             0       A060001001  A060000001           1  1585009031   \n",
       "1             0       A060001002  A060000001           1  1585009034   \n",
       "2             0       A060001003  A060000001           1  1585009042   \n",
       "3             0       A060001004  A060000001           1  1585009049   \n",
       "4             0       A060001005  A060000001           1  1585009056   \n",
       "...         ...              ...         ...         ...         ...   \n",
       "2526695    7395       A040122005  A040000122          -1  1599530720   \n",
       "2526696    7404       A030111005  A030000111          -1  1602582558   \n",
       "2526697    7416       A050193004  A050000193          -1  1601779481   \n",
       "2526698    7417       A050193004  A050000193          -1  1599397755   \n",
       "2526699    7439       A040130005  A040000130          -1  1602717003   \n",
       "\n",
       "         KnowledgeTag  hour  dow  elapsed  grade  ...  assessmentItemID_lf1  \\\n",
       "0                7224     0    1      0.0      6  ...              4.603269   \n",
       "1                7225     0    1      3.0      6  ...              4.547978   \n",
       "2                7225     0    1      8.0      6  ...              4.338867   \n",
       "3                7225     0    1      7.0      6  ...              4.595342   \n",
       "4                7225     0    1      7.0      6  ...              4.482671   \n",
       "...               ...   ...  ...      ...    ...  ...                   ...   \n",
       "2526695         10615     2    1      2.0      4  ...              1.302587   \n",
       "2526696          7636     9    1    107.0      3  ...              4.310803   \n",
       "2526697         10402     2    6     24.0      5  ...              1.639639   \n",
       "2526698         10402    13    6     21.0      5  ...              1.639639   \n",
       "2526699          8832    23    2     32.0      4  ...              1.574199   \n",
       "\n",
       "         assessmentItemID_lf2  assessmentItemID_lf3  assessmentItemID_lf4  \\\n",
       "0                   -1.805121             -5.570956              7.150968   \n",
       "1                   -1.742128             -5.559953              7.053310   \n",
       "2                   -1.651416             -5.316583              6.834635   \n",
       "3                   -1.797499             -5.573008              7.150943   \n",
       "4                   -1.714868             -5.472689              6.943464   \n",
       "...                       ...                   ...                   ...   \n",
       "2526695             -0.354698             -0.371282             -0.571389   \n",
       "2526696             -2.086544             -3.398213             -5.089712   \n",
       "2526697             -0.373915             -0.580215             -1.050618   \n",
       "2526698             -0.373915             -0.580215             -1.050618   \n",
       "2526699             -0.364823             -0.472768             -0.636377   \n",
       "\n",
       "         assessmentItemID_lf5  assessmentItemID_lf6  assessmentItemID_lf7  \\\n",
       "0                   -0.447569             -1.895929             -0.744443   \n",
       "1                   -0.449389             -1.861193             -0.735543   \n",
       "2                   -0.451975             -1.752899             -0.646381   \n",
       "3                   -0.453717             -1.892042             -0.745691   \n",
       "4                   -0.438975             -1.824496             -0.725131   \n",
       "...                       ...                   ...                   ...   \n",
       "2526695             -0.188631              1.780302             -0.904812   \n",
       "2526696              7.166411             -1.623552             -0.501869   \n",
       "2526697             -1.682823             -0.761719             -0.289506   \n",
       "2526698             -1.682823             -0.761719             -0.289506   \n",
       "2526699             -0.191183              2.262061             -1.170599   \n",
       "\n",
       "         assessmentItemID_lf8  assessmentItemID_lf9  assessmentItemID_lf10  \n",
       "0                   -0.781416             -0.003935               0.070115  \n",
       "1                   -0.779536             -0.001006               0.075968  \n",
       "2                   -0.687427             -0.000791               0.115197  \n",
       "3                   -0.778797             -0.002439               0.072494  \n",
       "4                   -0.789132              0.012729               0.077317  \n",
       "...                       ...                   ...                    ...  \n",
       "2526695             -0.700505              0.092521               0.054238  \n",
       "2526696             -0.839058             -0.063924               0.314202  \n",
       "2526697              0.458620             -0.383207               0.208749  \n",
       "2526698              0.458620             -0.383207               0.208749  \n",
       "2526699             -0.747868              0.100301               0.303518  \n",
       "\n",
       "[2526700 rows x 72 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userID</th>\n      <th>assessmentItemID</th>\n      <th>testId</th>\n      <th>answerCode</th>\n      <th>Timestamp</th>\n      <th>KnowledgeTag</th>\n      <th>hour</th>\n      <th>dow</th>\n      <th>elapsed</th>\n      <th>grade</th>\n      <th>...</th>\n      <th>assessmentItemID_lf1</th>\n      <th>assessmentItemID_lf2</th>\n      <th>assessmentItemID_lf3</th>\n      <th>assessmentItemID_lf4</th>\n      <th>assessmentItemID_lf5</th>\n      <th>assessmentItemID_lf6</th>\n      <th>assessmentItemID_lf7</th>\n      <th>assessmentItemID_lf8</th>\n      <th>assessmentItemID_lf9</th>\n      <th>assessmentItemID_lf10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>A060001001</td>\n      <td>A060000001</td>\n      <td>1</td>\n      <td>1585009031</td>\n      <td>7224</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>4.603269</td>\n      <td>-1.805121</td>\n      <td>-5.570956</td>\n      <td>7.150968</td>\n      <td>-0.447569</td>\n      <td>-1.895929</td>\n      <td>-0.744443</td>\n      <td>-0.781416</td>\n      <td>-0.003935</td>\n      <td>0.070115</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>A060001002</td>\n      <td>A060000001</td>\n      <td>1</td>\n      <td>1585009034</td>\n      <td>7225</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>4.547978</td>\n      <td>-1.742128</td>\n      <td>-5.559953</td>\n      <td>7.053310</td>\n      <td>-0.449389</td>\n      <td>-1.861193</td>\n      <td>-0.735543</td>\n      <td>-0.779536</td>\n      <td>-0.001006</td>\n      <td>0.075968</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>A060001003</td>\n      <td>A060000001</td>\n      <td>1</td>\n      <td>1585009042</td>\n      <td>7225</td>\n      <td>0</td>\n      <td>1</td>\n      <td>8.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>4.338867</td>\n      <td>-1.651416</td>\n      <td>-5.316583</td>\n      <td>6.834635</td>\n      <td>-0.451975</td>\n      <td>-1.752899</td>\n      <td>-0.646381</td>\n      <td>-0.687427</td>\n      <td>-0.000791</td>\n      <td>0.115197</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>A060001004</td>\n      <td>A060000001</td>\n      <td>1</td>\n      <td>1585009049</td>\n      <td>7225</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>4.595342</td>\n      <td>-1.797499</td>\n      <td>-5.573008</td>\n      <td>7.150943</td>\n      <td>-0.453717</td>\n      <td>-1.892042</td>\n      <td>-0.745691</td>\n      <td>-0.778797</td>\n      <td>-0.002439</td>\n      <td>0.072494</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>A060001005</td>\n      <td>A060000001</td>\n      <td>1</td>\n      <td>1585009056</td>\n      <td>7225</td>\n      <td>0</td>\n      <td>1</td>\n      <td>7.0</td>\n      <td>6</td>\n      <td>...</td>\n      <td>4.482671</td>\n      <td>-1.714868</td>\n      <td>-5.472689</td>\n      <td>6.943464</td>\n      <td>-0.438975</td>\n      <td>-1.824496</td>\n      <td>-0.725131</td>\n      <td>-0.789132</td>\n      <td>0.012729</td>\n      <td>0.077317</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2526695</th>\n      <td>7395</td>\n      <td>A040122005</td>\n      <td>A040000122</td>\n      <td>-1</td>\n      <td>1599530720</td>\n      <td>10615</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>1.302587</td>\n      <td>-0.354698</td>\n      <td>-0.371282</td>\n      <td>-0.571389</td>\n      <td>-0.188631</td>\n      <td>1.780302</td>\n      <td>-0.904812</td>\n      <td>-0.700505</td>\n      <td>0.092521</td>\n      <td>0.054238</td>\n    </tr>\n    <tr>\n      <th>2526696</th>\n      <td>7404</td>\n      <td>A030111005</td>\n      <td>A030000111</td>\n      <td>-1</td>\n      <td>1602582558</td>\n      <td>7636</td>\n      <td>9</td>\n      <td>1</td>\n      <td>107.0</td>\n      <td>3</td>\n      <td>...</td>\n      <td>4.310803</td>\n      <td>-2.086544</td>\n      <td>-3.398213</td>\n      <td>-5.089712</td>\n      <td>7.166411</td>\n      <td>-1.623552</td>\n      <td>-0.501869</td>\n      <td>-0.839058</td>\n      <td>-0.063924</td>\n      <td>0.314202</td>\n    </tr>\n    <tr>\n      <th>2526697</th>\n      <td>7416</td>\n      <td>A050193004</td>\n      <td>A050000193</td>\n      <td>-1</td>\n      <td>1601779481</td>\n      <td>10402</td>\n      <td>2</td>\n      <td>6</td>\n      <td>24.0</td>\n      <td>5</td>\n      <td>...</td>\n      <td>1.639639</td>\n      <td>-0.373915</td>\n      <td>-0.580215</td>\n      <td>-1.050618</td>\n      <td>-1.682823</td>\n      <td>-0.761719</td>\n      <td>-0.289506</td>\n      <td>0.458620</td>\n      <td>-0.383207</td>\n      <td>0.208749</td>\n    </tr>\n    <tr>\n      <th>2526698</th>\n      <td>7417</td>\n      <td>A050193004</td>\n      <td>A050000193</td>\n      <td>-1</td>\n      <td>1599397755</td>\n      <td>10402</td>\n      <td>13</td>\n      <td>6</td>\n      <td>21.0</td>\n      <td>5</td>\n      <td>...</td>\n      <td>1.639639</td>\n      <td>-0.373915</td>\n      <td>-0.580215</td>\n      <td>-1.050618</td>\n      <td>-1.682823</td>\n      <td>-0.761719</td>\n      <td>-0.289506</td>\n      <td>0.458620</td>\n      <td>-0.383207</td>\n      <td>0.208749</td>\n    </tr>\n    <tr>\n      <th>2526699</th>\n      <td>7439</td>\n      <td>A040130005</td>\n      <td>A040000130</td>\n      <td>-1</td>\n      <td>1602717003</td>\n      <td>8832</td>\n      <td>23</td>\n      <td>2</td>\n      <td>32.0</td>\n      <td>4</td>\n      <td>...</td>\n      <td>1.574199</td>\n      <td>-0.364823</td>\n      <td>-0.472768</td>\n      <td>-0.636377</td>\n      <td>-0.191183</td>\n      <td>2.262061</td>\n      <td>-1.170599</td>\n      <td>-0.747868</td>\n      <td>0.100301</td>\n      <td>0.303518</td>\n    </tr>\n  </tbody>\n</table>\n<p>2526700 rows × 72 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# truncatedSVD\n",
    "new_df = save_TSVD(K, whole_df)\n",
    "new_df"
   ]
  },
  {
   "source": [
    "## Split dataframe and Save it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = whole_df[whole_df['table']==0].sort_values(by='temp_idx').drop(columns=['table', 'temp_idx']).to_pickle(os.path.join(DATA_PATH,f'cv_train_data_FE_MF{K}.pkl'))\n",
    "valid_df = whole_df[whole_df['table']==1].sort_values(by='temp_idx').drop(columns=['table', 'temp_idx']).to_pickle(os.path.join(DATA_PATH,f'cv_valid_data_FE_MF{K}.pkl'))\n",
    "test_df = whole_df[whole_df['table']==2].sort_values(by='temp_idx').drop(columns=['table', 'temp_idx']).to_pickle(os.path.join(DATA_PATH,f'cv_test_data_FE_MF{K}.pkl'))\n",
    "\n"
   ]
  },
  {
   "source": [
    "## SVD\n",
    "memory overflow! unavaliable!  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Unavailable!",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-c9793f5eda2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# untruncated svd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unavailable!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pivot_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unavailable!"
     ]
    }
   ],
   "source": [
    "# untruncated svd\n",
    "raise RuntimeError(\"Unavailable!\")\n",
    "U, sigma, VT = svd(np.array(test_pivot_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smat= np.zeros((len(U),len(VT)))\n",
    "smat[:len(U),:len(U)] = np.diag(sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = test_pivot_df.index.values\n",
    "problems = test_pivot_df.columns.values\n",
    "\n",
    "# 유저 잠재 요인 - U\n",
    "user_latent_factor = {}\n",
    "\n",
    "# scaling\n",
    "U = U @ np.diag(sigma)\n",
    "\n",
    "for i, user in enumerate(users):\n",
    "    user_latent_factor[user] = U[i]\n",
    "\n",
    "# 문제 잠재 요인 - V\n",
    "problems_latent_factor = {}\n",
    "\n",
    "# scaling\n",
    "# VT = np.diag(sigma) @ VT\n",
    "VT = smat @ VT\n",
    "\n",
    "for i, problem in enumerate(problems):\n",
    "    problems_latent_factor[problem] = VT.T[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'TruncatedSVD' object is not callable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-eefdad3eeb8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 문제 잠재 요인들을 각 문제에 mapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnested_problems_lf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_svd_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'assessmentItemID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproblems_latent_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   3907\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3908\u001b[0m         \"\"\"\n\u001b[0;32m-> 3909\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3910\u001b[0m         return self._constructor(new_values, index=self.index).__finalize__(\n\u001b[1;32m   3911\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"map\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;31m# mapper is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'TruncatedSVD' object is not callable"
     ]
    }
   ],
   "source": [
    "# 문제 잠재 요인들을 각 문제에 mapping\n",
    "nested_problems_lf = test_svd_df['assessmentItemID'].map(problems_latent_factor).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nested numpy array를 하나의 numpy array로 변환\n",
    "problem_lf = np.concatenate(nested_problems_lf, 0).reshape(-1, nested_problems_lf[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 문제 잠재 요인을 기존 pandas DataFrame에 추가\n",
    "test_fe_df[[f'assessmentItemID_lf{i + 1}' for i in range(3)]] = problem_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fe_df"
   ]
  }
 ]
}